{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries and data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Debraj\\Anaconda3\\envs\\NLP_virtual\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3057: DtypeWarning: Columns (19,21,23,25,27,40,43,45,47,50,60,62,64,66,68,70,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,133,164,175,178,216,219,221,223,225,227,229,231,233,235,237,239,241,243,245,249,251,253,255,257,259,261,263,265,267,269,271,381,396,398,400,420,422,431,444,453,493,566,574,599,635,651,668,671,676,688,699,705,707,774,785,787,789,791,797,858,913,914,915,923,924,925,926,936,958,961,964) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "sns.set()\n",
    "\n",
    "df_NACC = pd.read_csv('./investigator_nacc46.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_NACC.groupby(['NACCID','DEMENTED']).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check if there is any NULL value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_NACC['DEMENTED'].isnull().sum()\n",
    "df_NACC.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering the records of first visits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_intial= df_NACC[df_NACC['PACKET']== \"I\"]\n",
    "df_intial['DEMENTED'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking the distribution of positive and negative examples in the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DEMENTED\n",
       "0    26478\n",
       "1    14380\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_intial.groupby(['DEMENTED']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40858, 965)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#size of the intial visit record \n",
    "df_intial.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Listing the columns to consider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "col2use =['NACCID', 'SEX', 'HISPANIC', 'PRIMLANG', 'EDUC', 'MARISTAT', 'NACCLIVS', 'INDEPEND', \\\n",
    "       'RESIDENC', 'NACCAGEB', 'NACCFAM','DEMENTED' ]\n",
    "col2test = ['SEX', 'HISPANIC', 'PRIMLANG', 'EDUC', 'MARISTAT', 'NACCLIVS', 'INDEPEND', \\\n",
    "         'RESIDENC', 'NACCAGEB', 'NACCFAM' ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data cleaning continued, removing irrelevant records using the dictionary from the documentation of NACC in the Neuropathology (NP) Data Set (https://www.alz.washington.edu/NONMEMBER/NP/rdd_np.pdf) and NACC Uniform Data set (UDS) (https://www.alz.washington.edu/WEB/rdd_uds.pdf) dictionaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_intial =df_intial[(df_intial['HISPANIC'] !=9)]\n",
    "df_intial = df_intial[(df_intial['PRIMLANG'] !=8) & (df_intial['PRIMLANG'] !=9)]\n",
    "df_intial = df_intial[(df_intial['EDUC'] <=36) & (df_intial['EDUC'] >=0)]\n",
    "df_intial = df_intial[(df_intial['MARISTAT'] != 9)]\n",
    "df_intial = df_intial[(df_intial['NACCLIVS'] != 9)]\n",
    "df_intial = df_intial[(df_intial['INDEPEND'] != 9)]\n",
    "df_intial = df_intial[(df_intial['RESIDENC'] != 9)] \n",
    "df_intial = df_intial[(df_intial['NACCAGEB'] >40)] \n",
    "df_intial = df_intial[(df_intial['NACCFAM'] !=-4) & (df_intial['NACCFAM'] != 9)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the cleaned data frame\n",
    "df = df_intial[col2use]\n",
    "df.reset_index(inplace= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing sklearn libraries for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler \n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forming the feature set and the corrosponding levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = df['DEMENTED'].values\n",
    "X = df[col2test].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run different classifier models with Gridsearch to find the optimal set of parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1728 candidates, totalling 8640 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    6.6s\n",
      "[Parallel(n_jobs=-1)]: Done 138 tasks      | elapsed:   37.6s\n",
      "[Parallel(n_jobs=-1)]: Done 341 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 624 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done 989 tasks      | elapsed:  4.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1434 tasks      | elapsed:  7.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1961 tasks      | elapsed: 10.5min\n",
      "[Parallel(n_jobs=-1)]: Done 2568 tasks      | elapsed: 14.6min\n",
      "[Parallel(n_jobs=-1)]: Done 3257 tasks      | elapsed: 19.8min\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "import numpy as np\n",
    "np.random.seed()\n",
    "import random\n",
    "random.seed()\n",
    "random_state = np.random.RandomState(42)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#Choose from any scaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import random\n",
    "random_state = np.random.RandomState(42)\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X_features, Y, test_size = 0.20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.20, random_state= random_state)\n",
    "#Scale the data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "# apply same transformation to test data\n",
    "X_test = scaler.transform(X_test)\n",
    "from sklearn import metrics\n",
    "# number of trees\n",
    "n_estimators = range(200,1000,200)\n",
    "# maximum number of features to use at each split\n",
    "max_features = ['auto','sqrt']\n",
    "# maximum depth of the tree\n",
    "max_depth = range(1,10,1)\n",
    "# minimum number of samples to split a node\n",
    "min_samples_split = range(2,10,2)\n",
    "# criterion for evaluating a split\n",
    "criterion = ['gini','entropy']\n",
    "\n",
    "param_grid = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': max_depth,\n",
    "    'max_features': max_features,\n",
    "    'min_samples_leaf': [3, 4, 5],\n",
    "    'min_samples_split': min_samples_split,\n",
    "    'n_estimators': n_estimators,\n",
    "    'criterion' : criterion  \n",
    "}\n",
    "\n",
    "rf_model=RandomForestClassifier()\n",
    "\n",
    "grid_rf = GridSearchCV(rf_model, param_grid = param_grid,\n",
    "                          cv =5 , n_jobs = -1, verbose= 2)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_rf.fit(X_train, y_train)\n",
    "print(\"the params\\n\", grid_rf.best_params_)\n",
    "print(\"Best score: %0.4f\" % grid_rf.best_score_)\n",
    "final_model = grid_rf.best_estimator_\n",
    "\n",
    "Y_pred = final_model.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "print(confusion_matrix(y_test,Y_pred))\n",
    "print(\"\\n\")\n",
    "print(classification_report(y_test,Y_pred))\n",
    "\n",
    "print(\"Training set score for RF: %f\" % final_model.score(X_train , y_train))\n",
    "print(\"Testing  set score for RF: %f\" % final_model.score(X_test  , y_test ))\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, Y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
